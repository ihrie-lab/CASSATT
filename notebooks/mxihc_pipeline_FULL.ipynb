{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 201 µs (started: 2022-01-06 13:20:56 -06:00)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from skimage import io, transform, util, img_as_float\n",
    "from skimage.filters import gaussian\n",
    "from skimage.color import separate_stains, hax_from_rgb, rgb2gray\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.util import img_as_ubyte, crop\n",
    "from skimage.draw import rectangle\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from skimage.measure import regionprops_table\n",
    "from skimage.segmentation import expand_labels, find_boundaries\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import napari\n",
    "import time\n",
    "import re\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "available_cores = multiprocessing.cpu_count()\n",
    "\n",
    "from stardist.models import StarDist2D\n",
    "from stardist import random_label_cmap\n",
    "from csbdeep.utils import normalize\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 657 µs (started: 2022-01-06 13:21:06 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# Set dev_mode to True to print step by step outputs to confirm pipeline is working as expected and find and correct issues\n",
    "dev_mode = True\n",
    "# Set batch_mode to False to run workflow on a single slide - ideal for setting up workflow for the first time. Set to True to run multiple slides at the same time.\n",
    "batch_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 889 µs (started: 2022-01-06 13:21:07 -06:00)\n"
     ]
    }
   ],
   "source": [
    "#set pipeline output directory\n",
    "output_dir = '/home/workstation/Python_Output'\n",
    "#set image input directory\n",
    "raw_img_dir = '/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN'  # for each round of imaging, images should be saved by the slide name and placed in a folder named for the marker that has been stained in the contained images\n",
    "# input order of MxIHC staining\n",
    "stain_order = ['PD-1', 'PD-L1', 'CD68', 'CD3', 'FoxP3', 'Iba-1', 'CD8', 'CD4']   # order in which antibodies were stained\n",
    "# input patient IDs\n",
    "slide_id = ['N14-248-1B', 'N14-692-2A', 'N14-945-2A', 'N15-501-1B', 'N16-244-2A', 'N16-478-2E']   \n",
    "# Stardist Model Directory\n",
    "stardist_dir = '/home/workstation/Dropbox (VU Basic Sciences)/Python Scripts/From ubuntu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.34 ms (started: 2022-01-06 13:21:09 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# Setting variables\n",
    "\n",
    "#BaseAligned image input\n",
    "input_folder = output_dir + '/BaseAligned'\n",
    "#Tiles output\n",
    "output_folder = output_dir + '/Tiled'\n",
    "# registered stack output\n",
    "reg_folder = output_dir + '/Registered'\n",
    "# cropped stack output\n",
    "crops_folder = output_dir + '/CroppedStacks'\n",
    "# reassembled registered slides output\n",
    "stitch_folder = output_dir + '/StitchedSlides'\n",
    "# nuclear labels output if using built in Stardist, input if importing segmentation\n",
    "labels_folder = output_dir + '/Labels'\n",
    "# plot outputs folder\n",
    "plots_folder = output_dir + '/Plots'\n",
    "\n",
    "tile_x, tile_y = 2048, 2048              # Can Edit Tile Size Here\n",
    "overlap_x, overlap_y = 512, 512          # Can Edit Overlap Here\n",
    "\n",
    "background_int = 250                     # Can Edit Mean Pixel Intensity for Tissue Detection Here (Sets mean pixel intensity value at which tiles are either discarded are saved during image tiling - saved blocks are noted with blue text in the tilemaps while discarded blocks are noted with red text)\n",
    "                                         # If tiles containing substantial tissue are discarded, adjust value higher, if tiles with no tissue are saved, adjust value lower\n",
    "\n",
    "_ransacReprojThreshold = 3               # Can Edit Maximum allowed reprojection error to treat a point pair as an inlier (used in the RANSAC method only) for Keypoint registration\n",
    "\n",
    "_num_good = 10                           # Can Edit Minimum number of good matches needed for keypoint registration to be considered successful\n",
    "_averageDistance = 0.5                   # Can Edit Maximum average distance of keypoint matches for registration to be considered successful\n",
    "\n",
    "\n",
    "stardist_segmentation = True            # Set to True if using stardist segmentation model, False if labels files will be generated and uploaded separately \n",
    "\n",
    "exp_lab_dist = 10                        # Can Edit pixel distance to expand nuclear labels to capture cytoplasmic signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Functions #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.8 ms (started: 2022-01-06 13:21:24 -06:00)\n"
     ]
    }
   ],
   "source": [
    "def closest(lst, K):    \r\n",
    "    return lst.index(lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))])\r\n",
    "\r\n",
    "\r\n",
    "def goalRes(file):\r\n",
    "    l_res = []\r\n",
    "    for index, page in enumerate(tifffile.TiffFile(file).pages):\r\n",
    "        try:\r\n",
    "            l_res.append([index, page.tags['XResolution'].value[1]])\r\n",
    "        except:\r\n",
    "            l_res.append([index, 0])    # catches pages where XResolution is not a valid tag\r\n",
    "    return closest([x[1] for x in l_res], 237000)   # this value is currently set specifically to return the 20X resolution image from specific SCN file type we get from DHSR\r\n",
    "    \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 ms (started: 2022-01-06 13:21:25 -06:00)\n"
     ]
    }
   ],
   "source": [
    "def deconvReg(image):\n",
    "    if type(image) == str:\n",
    "        img = io.imread(image)\n",
    "        hax  = separate_stains(img, hax_from_rgb)\n",
    "        hema = hax[:,:,0]\n",
    "        h = rescale_intensity(hema, in_range = (0, 0.1), out_range = 'uint8')  # in_range set to 0.1 here to get a stronger hema signal for better registration\n",
    "    elif type(image) == np.ndarray:\n",
    "        hax = separate_stains(image, hax_from_rgb)\n",
    "        hema = hax[:,:,0]\n",
    "        h = rescale_intensity(hema, in_range = (0, 0.1), out_range = 'uint8')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.22 ms (started: 2022-01-06 13:21:25 -06:00)\n"
     ]
    }
   ],
   "source": [
    "def base_align(base):\n",
    "    l_sizes =  []\n",
    "    test_img = io.imread(base[0])\n",
    "    for n in range(8):\n",
    "        l_sizes.append(int(test_img.shape[0]/2**n) * int(test_img.shape[1]/2**n))\n",
    "    scale_down = 2**closest(l_sizes, 3000000)\n",
    "    del test_img\n",
    "    \n",
    "    l_sim = []\n",
    "    if dev_mode == True:\n",
    "        f = open('{}/{}_distance.txt'.format(input_folder, os.path.splitext(os.path.basename(base[0]))[0]), 'w+')  \n",
    "    os.chdir(output_dir)\n",
    "    original_base_0 = io.imread(base[0])\n",
    "    tifffile.imwrite(output_dir + '/BaseAligned/Aligned_{}'.format(os.path.basename(base[0])), original_base_0)    # saves fixed image (untransformed)\n",
    "    base_0_gray = img_as_ubyte(rgb2gray(cv2.resize(original_base_0, (int(original_base_0.shape[1]/scale_down), int(original_base_0.shape[0]/scale_down)))))\n",
    "\n",
    "\n",
    "    for index, x in enumerate(base[1:]):\n",
    "        original_moving = io.imread(x)\n",
    "        moving_gray = img_as_ubyte(rgb2gray(cv2.resize(original_moving, (int(original_moving.shape[1]/scale_down), int(original_moving.shape[0]/scale_down)))))\n",
    "\n",
    "        \n",
    "        fd = cv2.KAZE_create(extended=True)\n",
    "        try:\n",
    "            moving_pts, target_pts, averageDistance, num_good = match_keypoints(moving_gray, base_0_gray, feature_detector=fd)\n",
    "            \n",
    "            transformer = transform.EuclideanTransform()\n",
    "            try:\n",
    "                transformer.estimate(target_pts * scale_down, moving_pts * scale_down)\n",
    "                output_shape_rc = original_base_0.shape[:2]\n",
    "                warped_img = transform.warp(original_moving, transformer, output_shape=output_shape_rc)\n",
    "            except:\n",
    "                if dev_mode == True:\n",
    "                    f.write('registration failure on ' + str(index+1) + ' apply_transform')\n",
    "                    f.close()\n",
    "                break\n",
    "            warped_img = img_as_ubyte(warped_img)\n",
    "            tifffile.imwrite(output_dir + '/BaseAligned/Aligned_{}'.format(os.path.basename(x)), warped_img)  # save transformed image    \n",
    "            warped_gray = img_as_ubyte(rgb2gray(cv2.resize(warped_img, (int(warped_img.shape[1]/scale_down), int(warped_img.shape[0]/scale_down)))))\n",
    "\n",
    "            gaus_base = gaussian(base_0_gray, 2)\n",
    "            gaus_warped = gaussian(warped_gray, 2)\n",
    "            gaus_moving = gaussian(moving_gray, 2)\n",
    "            X = metrics.structural_similarity(gaus_base, gaus_warped)\n",
    "            Y = metrics.structural_similarity(gaus_base, gaus_moving)\n",
    "            X1 = normalized_mutual_information(gaus_base, gaus_warped, bins = 100)\n",
    "            Y1 = normalized_mutual_information(gaus_base, gaus_moving, bins = 100)\n",
    "\n",
    "            l_sim.append([os.path.basename(x), X, Y, X1, Y1])\n",
    "\n",
    "            if dev_mode == True:\n",
    "                f.write('{}_Average Distance {} = {}________Number of Good Matches = {}\\n'.format(str(index+1),str(averageDistance),os.path.basename(x) ,str(num_good)))\n",
    "        except:\n",
    "            if dev_mode == True:\n",
    "                f.write('registration failure on ' + str(index+1) + ' match_keypoints.\\n')\n",
    "    df = pd.DataFrame(l_sim, columns = ['moving_file', 'warped_sim', 'moving_sim', 'warped_nmi', 'moving_nmi'])\n",
    "    df.to_csv(output_dir + '/BaseAligned/Similarity_{}.csv'.format(os.path.splitext(os.path.basename(x))[0]), index = False)\n",
    "    if dev_mode == True:\n",
    "        f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.1 ms (started: 2022-01-06 13:21:26 -06:00)\n"
     ]
    }
   ],
   "source": [
    "def tileSave(file):\n",
    "    tissue_detect = []\n",
    "    image = io.imread(file)\n",
    "    tile_rows_overlap = list(range(int(image.shape[0]/tile_x)))\n",
    "    tile_cols_overlap = list(range(int(image.shape[1]/tile_y)))\n",
    "    combined = [(f,s) for f in tile_rows_overlap for s in tile_cols_overlap]    \n",
    "    filename = os.path.basename(os.path.splitext(file)[0])   \n",
    "    _, _, _, pat, stain = filename.split('_')\n",
    "\n",
    "    os.makedirs('{}/{}'.format(output_folder, filename), exist_ok = True)\n",
    "    os.chdir('{}/{}'.format(output_folder,filename))\n",
    "\n",
    "\n",
    "    log = open('savelog.txt', 'w+')\n",
    "    \n",
    "    # Create low res slide image with tile rows and columns labeled\n",
    "    \n",
    "    imgScale = 0.25   # scale factor for low res slide image\n",
    "    newX, newY = int(image.shape[1]*imgScale), int(image.shape[0]*imgScale)\n",
    "    lowres = cv2.resize(image, (newX, newY))\n",
    "       \n",
    "     # Save cropped tiles\n",
    "\n",
    "    for i, j in combined: \n",
    "        row_top_offset = max(0, i * tile_x - overlap_x)\n",
    "        row_bot_offset = max(0, image.shape[0] - (tile_x * (i+1) + overlap_x))\n",
    "        col_l_offset = max(0, j * tile_y - overlap_y)\n",
    "        col_r_offset = max(0, image.shape[1] - (tile_y * (j+1) + overlap_y))  \n",
    "        croppedimg = crop(image,((row_top_offset,row_bot_offset),(col_l_offset, col_r_offset),(0,0)), copy = False)   \n",
    "        #tissue detection block\n",
    "        croppedimg[np.where((croppedimg==[0,0,0]).all(axis=2))] = [255,255,255]   # Turns black pixels white\n",
    "        tissue_detect.append([tile_rows_overlap[i], tile_cols_overlap[j], np.mean(croppedimg)])\n",
    "        TEXT = '({}, {})'.format(i, j)\n",
    "        TEXT_SCALE = 3                                                # font sizes may need to be adjusted if input image size change\n",
    "        TEXT_THICKNESS = 3\n",
    "        TEXT_FACE = 3\n",
    "        text_size, _ = cv2.getTextSize(TEXT, TEXT_FACE, TEXT_SCALE, TEXT_THICKNESS)\n",
    "        LOC = (int(j*tile_x*imgScale + (tile_x*imgScale)/2), int(i*tile_y*imgScale + (tile_y*imgScale)/2))\n",
    "        TEXT_ORG = (int(LOC[0]-text_size[0]/2), int(LOC[1] + text_size[1]/2))        \n",
    "        if np.mean(croppedimg) > background_int:    # if mean pixel intensity is less than background_int (default 250) (less white than 250, 250, 250) then saves tile.  otherwise tile is considered 'background' and discarded.  this value should be tweaked based on typical image background \n",
    "            alpha = 230\n",
    "            out_thick = 5\n",
    "            color = (alpha, alpha, alpha)\n",
    "            TL = (int(i*tile_x*imgScale), int(j*tile_x*imgScale))\n",
    "            TR = (int(i*tile_x*imgScale), int((j+1)*tile_x*imgScale))\n",
    "            BR = (int((i+1)*tile_x*imgScale), int((j+1)*tile_x*imgScale))\n",
    "            BL = (int((i+1)*tile_x*imgScale), int(j*tile_x*imgScale))\n",
    "\n",
    "            rr, cc = rectangle(start = TL, end =(TR[0] + out_thick, TR[1]), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color\n",
    "            rr, cc = rectangle(start = TR, end = (BR[0], BR[1]-out_thick), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color\n",
    "            rr, cc = rectangle(start = BL, end = (BR[0] - out_thick, BR[1]), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color\n",
    "            rr,cc = rectangle(start = TL, end = (BL[0], BL[1] + out_thick), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color\n",
    "            cv2.putText(lowres, text = TEXT, org = TEXT_ORG, fontFace = TEXT_FACE, fontScale = TEXT_SCALE, color = color, thickness = TEXT_THICKNESS)     \n",
    "    for i, j in combined:\n",
    "        row_top_offset = max(0, i * tile_x - overlap_x)\n",
    "        row_bot_offset = max(0, image.shape[0] - (tile_x * (i+1) + overlap_x))\n",
    "        col_l_offset = max(0, j * tile_y - overlap_y)\n",
    "        col_r_offset = max(0, image.shape[1] - (tile_y * (j+1) + overlap_y))  \n",
    "        croppedimg = crop(image,((row_top_offset,row_bot_offset),(col_l_offset, col_r_offset),(0,0)), copy = False)   \n",
    "        #tissue detection block\n",
    "        croppedimg[np.where((croppedimg==[0,0,0]).all(axis=2))] = [255,255,255]   # Turns black pixels white\n",
    "        tissue_detect.append([tile_rows_overlap[i], tile_cols_overlap[j], np.mean(croppedimg)])\n",
    "        TEXT = '({}, {})'.format(i, j)\n",
    "        TEXT_SCALE = 3                                                # font sizes may need to be adjusted if input image size change\n",
    "        TEXT_THICKNESS = 3\n",
    "        TEXT_FACE = 3\n",
    "        text_size, _ = cv2.getTextSize(TEXT, TEXT_FACE, TEXT_SCALE, TEXT_THICKNESS)\n",
    "        LOC = (int(j*tile_x*imgScale + (tile_x*imgScale)/2), int(i*tile_y*imgScale + (tile_y*imgScale)/2))\n",
    "        TEXT_ORG = (int(LOC[0]-text_size[0]/2), int(LOC[1] + text_size[1]/2))        \n",
    "\n",
    "        if np.mean(croppedimg) < background_int:    # if mean pixel intensity is less than background_int (default 250) (less white than 250, 250, 250) then saves tile.  otherwise tile is considered 'background' and discarded.  this value should be tweaked based on typical image background \n",
    "            io.imsave('{}_{}_r{}_c{}.tiff'.format(pat, stain, tile_rows_overlap[i], tile_cols_overlap[j]), croppedimg)\n",
    "            cv2.putText(lowres, text = TEXT, org = TEXT_ORG, fontFace = TEXT_FACE, fontScale = TEXT_SCALE, color = (0,0,0), thickness = TEXT_THICKNESS)  \n",
    "            alpha = 0\n",
    "            out_thick = 5\n",
    "            color = (alpha, alpha, alpha)\n",
    "            TL = (int(i*tile_x*imgScale), int(j*tile_x*imgScale))\n",
    "            TR = (int(i*tile_x*imgScale), int((j+1)*tile_x*imgScale))\n",
    "            BR = (int((i+1)*tile_x*imgScale), int((j+1)*tile_x*imgScale))\n",
    "            BL = (int((i+1)*tile_x*imgScale), int(j*tile_x*imgScale))\n",
    "\n",
    "            rr, cc = rectangle(start = (TL[0]-out_thick, TL[1]-out_thick), end =(TR[0] + out_thick, TR[1]-out_thick), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color\n",
    "            rr, cc = rectangle(start = (TR[0]+out_thick, TR[1]-out_thick), end = (BR[0]+out_thick, BR[1]+out_thick), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color\n",
    "            rr, cc = rectangle(start = (BL[0]-out_thick, BL[1]+out_thick), end = (BR[0] + out_thick, BR[1]+out_thick), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color\n",
    "            rr,cc = rectangle(start = (TL[0]-out_thick, TL[1]-out_thick), end = (BL[0]-out_thick, BL[1] + out_thick), shape = lowres.shape)\n",
    "            lowres[rr,cc] = color  \n",
    "    io.imsave('{}/{}_{}_tilemap.tiff'.format(output_folder, pat, stain), lowres)\n",
    "    df_tissue_detect = pd.DataFrame(tissue_detect, columns = ['row', 'col', 'mean_int'])\n",
    "    df_tissue_detect.to_csv('{}/{}_{}_tissue_detect.csv'.format(output_folder, pat, stain), index = False)\n",
    "    log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.12 ms (started: 2022-01-06 13:21:26 -06:00)\n"
     ]
    }
   ],
   "source": [
    "def match_keypoints(moving, target, feature_detector):\n",
    "\n",
    "    kp1, desc1 = feature_detector.detectAndCompute(moving, None)\n",
    "    kp2, desc2 = feature_detector.detectAndCompute(target, None)\n",
    "\n",
    "    matcher = cv2.BFMatcher(normType=cv2.NORM_L2, crossCheck=True)\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "    matches_sorted = sorted(matches, key = lambda x: x.distance)\n",
    "    \n",
    "    totalDistance = 0\n",
    "    for g in matches_sorted:\n",
    "        totalDistance += g.distance\n",
    "        \n",
    "    if len(matches_sorted) == 0:\n",
    "        averageDistance = 0\n",
    "    else:\n",
    "        averageDistance = totalDistance/len(matches_sorted)\n",
    "\n",
    "\n",
    "    src_match_idx = [m.queryIdx for m in matches_sorted[:200]]   # list only first 200 matches can edit to select more or less\n",
    "    dst_match_idx = [m.trainIdx for m in matches_sorted[:200]]\n",
    "\n",
    "    src_points = np.float32([kp1[i].pt for i in src_match_idx])\n",
    "    dst_points = np.float32([kp2[i].pt for i in dst_match_idx])\n",
    "\n",
    "    H, mask = cv2.findHomography(src_points, dst_points, cv2.RANSAC, ransacReprojThreshold=_ransacReprojThreshold)   # original value = 7 \n",
    "\n",
    "    good = [matches_sorted[i] for i in np.arange(0, len(mask)) if mask[i] == [1]]\n",
    "    \n",
    "    num_good = len(good) # count how many good matches were found\n",
    "\n",
    "    filtered_src_match_idx = [m.queryIdx for m in good]\n",
    "    filtered_dst_match_idx = [m.trainIdx for m in good]\n",
    "\n",
    "    filtered_src_points = np.float32([kp1[i].pt for i in filtered_src_match_idx])\n",
    "    filtered_dst_points = np.float32([kp2[i].pt for i in filtered_dst_match_idx])\n",
    "\n",
    "    return filtered_src_points, filtered_dst_points, averageDistance, num_good\n",
    "\n",
    "def apply_transform(moving, target, moving_pts, target_pts, transformer, output_shape_rc=None):\n",
    "\n",
    "    if output_shape_rc is None:\n",
    "        output_shape_rc = target.shape[:2]\n",
    "\n",
    "    if str(transformer.__class__) == \"<class 'skimage.transform.EuclideanTransform'>\":\n",
    "        transformer.estimate(target_pts, moving_pts)\n",
    "        warped_img = transform.warp(moving, transformer, output_shape=output_shape_rc)\n",
    "\n",
    "        ### Restimate to warp points\n",
    "        transformer.estimate(moving_pts, target_pts)\n",
    "        warped_pts = transformer(moving_pts)\n",
    "    else:\n",
    "        transformer.estimate(moving_pts, target_pts)\n",
    "        warped_img = transform.warp(moving, transformer.inverse, output_shape=output_shape_rc)\n",
    "        warped_pts = transformer(moving_pts)\n",
    "\n",
    "    return warped_img, warped_pts\n",
    "\n",
    "def keypoint_distance(moving_pts, target_pts, img_h, img_w):\n",
    "    dst = np.sqrt(np.sum((moving_pts - target_pts)**2, axis=1)) / np.sqrt(img_h**2 + img_w**2)\n",
    "    return np.mean(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.72 ms (started: 2022-01-06 13:21:27 -06:00)\n"
     ]
    }
   ],
   "source": [
    "def regAll(path):\n",
    "    os.makedirs('{}/{}'.format(\n",
    "        reg_folder,\n",
    "        os.path.basename(path)), exist_ok = True)\n",
    "    os.chdir('{}/{}'.format(\n",
    "        reg_folder,\n",
    "        os.path.basename(path)))\n",
    "    if dev_mode == True:\n",
    "        f = open('{}/{}/distance.txt'.format(\n",
    "                reg_folder,\n",
    "                os.path.basename(path)), 'w+')   \n",
    "    \n",
    "    d_reg = {}\n",
    "    for i, k in enumerate(all_paths[path]):      \n",
    "        # block for registering image to stain_order0\n",
    "\n",
    "        original_target = io.imread(all_paths[path][0])  # rgb input\n",
    "        original_moving = io.imread(k)  # rgb\n",
    "\n",
    "        target_file = deconvReg(all_paths[path][0])   # Hema only\n",
    "        moving_file = deconvReg(k)   # Hema only\n",
    "\n",
    "        target = img_as_ubyte(gaussian(target_file, 3))    #blur on hema\n",
    "        moving = img_as_ubyte(gaussian(moving_file, 3))    #blur on hema\n",
    "                                                           #gaussian alpha can be tuned here\n",
    "        _, stainord, _, slide, stain = os.path.basename(os.path.dirname(k)).split('_')\n",
    "        _, _, row, col = os.path.basename(os.path.splitext(k)[0]).split('_')\n",
    "\n",
    "        fd = cv2.KAZE_create(extended=True)\n",
    "        try:\n",
    "            moving_pts, target_pts, averageDistance, num_good = match_keypoints(moving, target, feature_detector=fd)\n",
    "        except:\n",
    "            if dev_mode == True:\n",
    "                f.write('registration failure on' + str(i) + 'match_keypoints')\n",
    "                f.close()\n",
    "            break\n",
    "        if dev_mode == True:\n",
    "            f.write('{}_Average Distance {} = {}________Number of Good Matches = {}\\n'.format(str(i),str(averageDistance), all_paths[path][i],str(num_good)))\n",
    "\n",
    "        transformer = transform.EuclideanTransform()\n",
    "        try:\n",
    "            warped_img, warped_pts = apply_transform(original_moving, original_target, moving_pts, target_pts, transformer=transformer)\n",
    "        except:\n",
    "            if dev_mode == True:\n",
    "                f.write('registration failure on' + str(i) + 'apply_transform')\n",
    "                f.close()\n",
    "            break\n",
    "\n",
    "        warped_img = img_as_ubyte(warped_img)\n",
    "        d_reg[int(stainord),'i0'] = warped_img \n",
    "        if dev_mode == True:\n",
    "            io.imsave(str(i) + '_i0_' + (os.path.basename(os.path.splitext(all_paths[path][i])[0])+ '_reg.tiff'), warped_img)\n",
    "\n",
    "        \n",
    "        \n",
    "        # if a suboptimal registration is detected via low number of good keypoint matches or large average distance between matches\n",
    "        # instead of registering to the index0 image, attemp to register to the index -1 image (previous image in registration stack)\n",
    "        if num_good < _num_good or averageDistance > _averageDistance:  \n",
    "            \n",
    "            if (int(stainord)-1, 'i-1') in d_reg.keys():\n",
    "                original_target = d_reg[int(stainord)-1, 'i-1']\n",
    "            else:\n",
    "                original_target = d_reg[int(stainord)-1, 'i0']\n",
    "                \n",
    "            if (int(stainord)-1, 'i-1') in d_reg.keys():\n",
    "                target_file = deconvReg(d_reg[int(stainord)-1, 'i-1'])\n",
    "            else:\n",
    "                target_file = deconvReg(d_reg[int(stainord)-1, 'i0'])\n",
    "\n",
    "\n",
    "            target = img_as_ubyte(gaussian(target_file, 6))    #alpha could be tuned for best performace \n",
    "            moving = img_as_ubyte(gaussian(moving_file, 6))\n",
    "\n",
    "\n",
    "            fd = cv2.KAZE_create(extended=True)\n",
    "            try:\n",
    "                moving_pts, target_pts, averageDistance, num_good = match_keypoints(moving, target, feature_detector=fd)\n",
    "            except:\n",
    "                if dev_mode == True:\n",
    "                    f.write('fail on' + str(i) + '-1 match_keypoints')\n",
    "                    f.close()\n",
    "                break\n",
    "            if dev_mode == True:\n",
    "                f.write('{}_i-1_Average Distance {} = {}________Number of Good Matches = {}\\n'.format(str(i),str(averageDistance), all_paths[path][i],str(num_good)))\n",
    "\n",
    "            transformer = transform.EuclideanTransform()\n",
    "            try:\n",
    "                warped_img2, warped_pts2 = apply_transform(original_moving, original_target, moving_pts, target_pts, transformer=transformer)\n",
    "            except:\n",
    "                if dev_mode == True:\n",
    "                    f.write('fail on' + str(i) + '-1 apply_transform')\n",
    "                    f.close()\n",
    "                break\n",
    "            warped_img2 = img_as_ubyte(warped_img2)\n",
    "            if num_good<10 or averageDistance > 0.5:\n",
    "                break\n",
    "            else:\n",
    "                d_reg[int(stainord), 'i-1'] = warped_img2\n",
    "                if dev_mode == True:\n",
    "                    io.imsave(str(i)+'_i-1_' + (os.path.basename(os.path.splitext(all_paths[path][i])[0]+ '_reg.tiff')), warped_img2)\n",
    "\n",
    "                continue\n",
    "            break\n",
    "    if dev_mode == True:\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    \n",
    "    #combine mask on d_reg\n",
    "    l_reg_sort = [list(g) for k, g in groupby(list(d_reg.keys()), key = lambda x: x[0])]  # sort files by first character (original and i-1 image will both have same number preceding) # need to update to allow for numbers > 10\n",
    "    l_reg_filter = []\n",
    "    for h in l_reg_sort:         # if i-1 image exists, take it if not take the regular registered image\n",
    "        if len(h) == 1:\n",
    "            l_reg_filter.append(d_reg[h[0]])\n",
    "        if len(h) == 2:\n",
    "            l_reg_filter.append(d_reg[h[1]])\n",
    "\n",
    "    combined_mask = np.zeros((l_reg_filter[0].shape[0],l_reg_filter[0].shape[1]), dtype=bool)    # create empty mask file with same shape as images\n",
    "    for k in l_reg_filter:\n",
    "        if len(l_reg_filter) == len(stain_order):     # only take tiles where we have an image for every stain in stain_order\n",
    "            k[np.all(k == (0,0,0), axis = -1)] = (255, 255,255)  # set black registration gaps to white\n",
    "            gaus = gaussian(k, 6, multichannel = True)  # apply gaussian blur to image, returns float\n",
    "\n",
    "            thresh = 0.97    # Try range of values to determine ideal threshold\n",
    "            mask_gaus = (gaus[:,:,1] ==0) | ((gaus[:,:,0] > thresh) | (gaus[:,:,1] > thresh) | (gaus[:,:,2] > thresh)) # masks any image area where pixel value is either 0 or above threshold on any of the 3 channels\n",
    "            combined_mask = combined_mask + mask_gaus\n",
    "        else:\n",
    "            break\n",
    "    else:     \n",
    "        clean_mask = remove_small_objects(combined_mask, min_size=2000)   # can edit size of small objects / small holes here\n",
    "        clean_mask = remove_small_holes(clean_mask, area_threshold=2000)\n",
    "        if dev_mode == True:\n",
    "            io.imsave('{}_{}_{}_CombinedMask.tiff'.format(slide, row, col), img_as_ubyte(clean_mask))   #save combined mask file\n",
    "        arrays = []\n",
    "        for y in l_reg_filter:\n",
    "            y[np.all(y == (0,0,0), axis = -1)] = (250, 250,250)\n",
    "            y[clean_mask] = 250\n",
    "            arrays.append(y)\n",
    "        stack = np.stack(arrays, axis = 0)\n",
    "        io.imsave('{}_{}_{}_stack.tiff'.format(slide, row, col), stack)\n",
    "        if dev_mode == True:\n",
    "            demo = l_reg_filter[0]   # apply mask to index 0 stain as example       \n",
    "            gaps = demo[:,:,1] == 0\n",
    "            demo[gaps] = 250\n",
    "            demo[clean_mask] = 250\n",
    "            io.imsave('{}_{}_{}_demo.tiff'.format(slide, row, col), demo)   # save an example of the mask on image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Base Alignment of Full Slide Images #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.31 ms (started: 2022-01-06 13:21:28 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# create subfolders in output folder\n",
    "os.chdir(output_dir)\n",
    "os.makedirs(output_dir + '/BaseImages', exist_ok = True)\n",
    "os.makedirs(input_folder, exist_ok = True)\n",
    "os.makedirs(stitch_folder, exist_ok = True)\n",
    "os.makedirs(crops_folder, exist_ok = True)\n",
    "os.makedirs(labels_folder, exist_ok = True)\n",
    "os.makedirs(plots_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected PD-1 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-1/N14-248-1B.scn\n",
      "Expected PD-L1 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-L1/N14-248-1B.scn\n",
      "Expected CD68 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD68/N14-248-1B.scn\n",
      "Expected CD3 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD3/N14-248-1B.scn\n",
      "Expected FoxP3 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/FoxP3/N14-248-1B.scn\n",
      "Expected Iba-1 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/Iba-1/N14-248-1B.scn\n",
      "Expected CD8 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD8/N14-248-1B.scn\n",
      "Expected CD4 N14-248-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD4/N14-248-1B.scn\n",
      "Expected PD-1 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-1/N14-692-2A.scn\n",
      "Expected PD-L1 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-L1/N14-692-2A.scn\n",
      "Expected CD68 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD68/N14-692-2A.scn\n",
      "Expected CD3 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD3/N14-692-2A.scn\n",
      "Expected FoxP3 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/FoxP3/N14-692-2A.scn\n",
      "Expected Iba-1 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/Iba-1/N14-692-2A.scn\n",
      "Expected CD8 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD8/N14-692-2A.scn\n",
      "Expected CD4 N14-692-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD4/N14-692-2A.scn\n",
      "Expected PD-1 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-1/N14-945-2A.scn\n",
      "Expected PD-L1 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-L1/N14-945-2A.scn\n",
      "Expected CD68 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD68/N14-945-2A.scn\n",
      "Expected CD3 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD3/N14-945-2A.scn\n",
      "Expected FoxP3 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/FoxP3/N14-945-2A.scn\n",
      "Expected Iba-1 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/Iba-1/N14-945-2A.scn\n",
      "Expected CD8 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD8/N14-945-2A.scn\n",
      "Expected CD4 N14-945-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD4/N14-945-2A.scn\n",
      "Expected PD-1 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-1/N15-501-1B.scn\n",
      "Expected PD-L1 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-L1/N15-501-1B.scn\n",
      "Expected CD68 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD68/N15-501-1B.scn\n",
      "Expected CD3 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD3/N15-501-1B.scn\n",
      "Expected FoxP3 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/FoxP3/N15-501-1B.scn\n",
      "Expected Iba-1 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/Iba-1/N15-501-1B.scn\n",
      "Expected CD8 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD8/N15-501-1B.scn\n",
      "Expected CD4 N15-501-1B file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD4/N15-501-1B.scn\n",
      "Expected PD-1 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-1/N16-244-2A.scn\n",
      "Expected PD-L1 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-L1/N16-244-2A.scn\n",
      "Expected CD68 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD68/N16-244-2A.scn\n",
      "Expected CD3 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD3/N16-244-2A.scn\n",
      "Expected FoxP3 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/FoxP3/N16-244-2A.scn\n",
      "Expected Iba-1 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/Iba-1/N16-244-2A.scn\n",
      "Expected CD8 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD8/N16-244-2A.scn\n",
      "Expected CD4 N16-244-2A file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD4/N16-244-2A.scn\n",
      "Expected PD-1 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-1/N16-478-2E.scn\n",
      "Expected PD-L1 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-L1/N16-478-2E.scn\n",
      "Expected CD68 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD68/N16-478-2E.scn\n",
      "Expected CD3 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD3/N16-478-2E.scn\n",
      "Expected FoxP3 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/FoxP3/N16-478-2E.scn\n",
      "Expected Iba-1 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/Iba-1/N16-478-2E.scn\n",
      "Expected CD8 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD8/N16-478-2E.scn\n",
      "Expected CD4 N16-478-2E file = /media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD4/N16-478-2E.scn\n",
      "time: 9.55 ms (started: 2022-01-06 13:21:36 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# create list of lists of paths to raw images for each slide stains in imaged order\n",
    "all_slides = []\n",
    "for y in slide_id:\n",
    "    slide_names = []\n",
    "    for root, dirs, files in os.walk(raw_img_dir):\n",
    "        for i in files:\n",
    "            if os.path.splitext(i)[1] in ['.scn', '.svs']:\n",
    "                if os.path.splitext(i)[0] == y:\n",
    "                    stain = os.path.basename(os.path.dirname(os.path.join(root, i)))\n",
    "                    stain_ord = stain_order.index(stain)\n",
    "                    slide_names.append(tuple([stain_ord, os.path.join(root, i)]))\n",
    "\n",
    "    slide_names = sorted(slide_names)\n",
    "    slide_names = [x[1] for x in slide_names]\n",
    "    all_slides.append(slide_names)\n",
    "\n",
    "#checks that for each sample, raw image file exists for every file and are in the correct order\n",
    "if dev_mode == True:\n",
    "    for index, l in enumerate(all_slides):\n",
    "        for indexx, ll in enumerate(l):\n",
    "            print('Expected ' + stain_order[indexx] +' '+ slide_id[index] + ' file = ' +  ll)\n",
    "            assert os.path.basename(os.path.dirname(ll)) == stain_order[indexx] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide index = 0 slide_id = N14-248-1B\n",
      "slide index = 1 slide_id = N14-692-2A\n",
      "slide index = 2 slide_id = N14-945-2A\n",
      "slide index = 3 slide_id = N15-501-1B\n",
      "slide index = 4 slide_id = N16-244-2A\n",
      "slide index = 5 slide_id = N16-478-2E\n",
      "time: 810 µs (started: 2022-01-06 16:39:10 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# Choose slide to run pipeline on\n",
    "if batch_mode == False:\n",
    "    for index, slide in enumerate(slide_id):\n",
    "        print('slide index = '+str(index) + ' slide_id = ' +slide)\n",
    "\n",
    "    test_slide_index = 3   # if batch_mode = False, set index of single slide to run workflow on here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-1/N15-501-1B.scn (40960, 28672, 3)\n",
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/PD-L1/N15-501-1B.scn (40960, 28672, 3)\n",
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD68/N15-501-1B.scn (40960, 28672, 3)\n",
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD3/N15-501-1B.scn (40960, 28672, 3)\n",
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/FoxP3/N15-501-1B.scn (40960, 28672, 3)\n",
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/Iba-1/N15-501-1B.scn (40960, 28672, 3)\n",
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD8/N15-501-1B.scn (40960, 28672, 3)\n",
      "/media/workstation/Backup Drive/Ihrie_MxIHC_2020/SCN/CD4/N15-501-1B.scn (40960, 28672, 3)\n",
      "time: 39.2 s (started: 2022-01-06 16:39:13 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# Open and resave raw images cropped to the nearest multiple of tile_x and tile_y pixels in x, y dimensions\n",
    "if batch_mode == False:\n",
    "    for y in [all_slides[test_slide_index]]:\n",
    "        l_shapes = []\n",
    "        for index, slide in enumerate(y):\n",
    "            img = tifffile.imread(slide, key = goalRes(slide))    # watch out for if within an image set, output shapes change\n",
    "            crop_row = (img.shape[0]%tile_x)\n",
    "            crop_col = (img.shape[1]%tile_y)\n",
    "            out_image = crop(img, ((int(math.floor(crop_row/2)), int(math.ceil(crop_row/2))), (int(math.floor(crop_col/2)), int(math.ceil(crop_col/2))), (0,0)), copy = False)\n",
    "            if dev_mode == True:\n",
    "                print(slide , out_image.shape)\n",
    "            l_shapes.append(out_image.shape)\n",
    "            tifffile.imwrite(output_dir + f'/BaseImages/{index}_Base_{os.path.basename(os.path.splitext(slide)[0])}_{os.path.basename(os.path.dirname(slide))}.tiff', out_image, photometric='minisblack') \n",
    "        assert len(set(l_shapes))<=1 # ensures that all images are the same dimensions\n",
    "else: \n",
    "    for y in all_slides:\n",
    "        l_shapes = []\n",
    "        for index, slide in enumerate(y):\n",
    "            img = tifffile.imread(slide, key = goalRes(slide))    # watch out for if within an image set, output shapes change\n",
    "            crop_row = (img.shape[0]%tile_x)\n",
    "            crop_col = (img.shape[1]%tile_y)\n",
    "            out_image = crop(img, ((int(math.floor(crop_row/2)), int(math.ceil(crop_row/2))), (int(math.floor(crop_col/2)), int(math.ceil(crop_col/2))), (0,0)), copy = False)\n",
    "            if dev_mode == True:\n",
    "                print(slide , out_image.shape)\n",
    "            l_shapes.append(out_image.shape)\n",
    "            tifffile.imwrite(output_dir + f'/BaseImages/{index}_Base_{os.path.basename(os.path.splitext(slide)[0])}_{os.path.basename(os.path.dirname(slide))}.tiff', out_image, photometric='minisblack') \n",
    "        assert len(set(l_shapes))<=1 # ensures that all images are the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.72 ms (started: 2022-01-06 16:39:52 -06:00)\n"
     ]
    }
   ],
   "source": [
    "l_base = []\n",
    "for y in slide_id:\n",
    "    slide_names = []\n",
    "    for files in os.listdir(output_dir + '/BaseImages'):\n",
    "        _, _, pat, stain = os.path.splitext(files)[0].split('_')\n",
    "        if pat == y:\n",
    "            stain_ord = stain_order.index(stain)\n",
    "            slide_names.append(tuple([stain_ord, os.path.join(output_dir+ '/BaseImages/' ,files)]))\n",
    "    slide_names = sorted(slide_names)\n",
    "    slide_names = [x[1] for x in slide_names]\n",
    "    l_base.append(slide_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18min 4s (started: 2022-01-06 16:39:52 -06:00)\n"
     ]
    }
   ],
   "source": [
    "if batch_mode == False:\n",
    "    base_align(l_base[test_slide_index])\n",
    "else:\n",
    "    Parallel(n_jobs = 1)(delayed(base_align)(file) for file in tqdm(l_base))   # decrease n_jobs if running out of memory on this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 968 µs (started: 2022-01-06 16:57:57 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# collects all base_aligned files \n",
    "l_files = sorted(glob.glob(input_folder + '/*.tiff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (30720, 16384, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/home/workstation/tensor_env/lib/python3.8/site-packages/napari/_vispy/vispy_image_layer.py:183: UserWarning: data shape (40960, 32768, 3) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8min 3s (started: 2022-01-06 14:24:00 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# dev mode:open base aligned images in napari \n",
    "if dev_mode == True and batch_mode == False:\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(io.imread(l_files[0]), name = os.path.basename(l_files[0]))\n",
    "        for file in l_files[1:]:\n",
    "            viewer.add_image(io.imread(file), name = os.path.basename(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tile Image and Register #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/workstation/Python_Output/BaseAligned/Aligned_0_Base_N14-945-2A_PD-1.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_0_Base_N16-244-2A_PD-1.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_1_Base_N14-945-2A_PD-L1.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_1_Base_N16-244-2A_PD-L1.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_2_Base_N14-945-2A_CD68.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_2_Base_N16-244-2A_CD68.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_3_Base_N14-945-2A_CD3.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_3_Base_N16-244-2A_CD3.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_4_Base_N14-945-2A_FoxP3.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_4_Base_N16-244-2A_FoxP3.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_5_Base_N14-945-2A_Iba-1.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_5_Base_N16-244-2A_Iba-1.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_6_Base_N14-945-2A_CD8.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_6_Base_N16-244-2A_CD8.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_7_Base_N14-945-2A_CD4.tiff',\n",
       " '/home/workstation/Python_Output/BaseAligned/Aligned_7_Base_N16-244-2A_CD4.tiff']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.62 ms (started: 2022-01-06 14:32:03 -06:00)\n"
     ]
    }
   ],
   "source": [
    "l_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 10740.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 7s (started: 2022-01-06 16:57:57 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# Crop and save all tiles from all base aligned images\n",
    "Parallel(n_jobs = int(available_cores * 0.9))(delayed(tileSave)(file)for file in tqdm(l_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 3s (started: 2022-01-06 14:35:13 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# list tilemaps and open in napari\n",
    "if dev_mode == True and batch_mode == False:\n",
    "    l_tilemaps = sorted(glob.glob(output_folder + '/*_tilemap.tiff'))  \n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(io.imread(l_tilemaps[0]), name = os.path.basename(l_tilemaps[0]))\n",
    "        for file in l_tilemaps[1:]:\n",
    "            viewer.add_image(io.imread(file), name = os.path.basename(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.2 ms (started: 2022-01-06 17:02:04 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# list all tiles for a slide\n",
    "l_allfiles = []\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('_reg.tiff') | file.endswith('_tilemap.tiff'):\n",
    "            continue\n",
    "        if os.path.basename(root) == 'mask':\n",
    "            continue\n",
    "        if file.endswith('.tiff'):\n",
    "            l_allfiles.append(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.1 ms (started: 2022-01-06 17:02:04 -06:00)\n"
     ]
    }
   ],
   "source": [
    "#Extract metadata for each cropped image from file names\n",
    "metadata = []\n",
    "for path in l_allfiles:\n",
    "    file = os.path.basename(os.path.splitext(path)[0])\n",
    "    slide,stain,row,col = file.split('_')\n",
    "    coord = row+col\n",
    "    stain_ord = stain_order.index(stain)\n",
    "    file_meta = [slide, stain, stain_ord, coord, path]\n",
    "    metadata.append(file_meta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.18 ms (started: 2022-01-06 17:02:04 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# Filter all cropped images for first stain as baseline to register all other images to\n",
    "stain0_list = [item for item in metadata if item[1] == stain_order[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 146 ms (started: 2022-01-06 17:02:05 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# For each cropped stain_order[0] image, find all files that are from the matching row - col location of the slide.  \n",
    "# If a matching crop does not exist in all files, eliminate.\n",
    "# Creates dict with key = stain_order[0] path and values = all matching tile paths in stain order\n",
    "# Creates list of all stain_order[0] paths where all stain channel images exist to iterate through\n",
    "all_paths = {}\n",
    "l_stain0_filter = []\n",
    "for coord in stain0_list:\n",
    "    files = [item for item in metadata if (item[0] == coord[0] and item[3] == coord[3])]\n",
    "    if len(files) == len(stain_order):\n",
    "        for i in files:\n",
    "            files = sorted(files, key = lambda x: x[2])\n",
    "            if i[1] == stain_order[0]:\n",
    "                l_stain0_filter.append(i[4])\n",
    "            file_paths = [item[4] for item in files]\n",
    "            key = [item[4] for item in files if item[1] == stain_order[0]]\n",
    "            all_paths[key[0]] = file_paths\n",
    "l_stain0_filter = sorted(l_stain0_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 5s (started: 2022-01-06 17:02:05 -06:00)\n"
     ]
    }
   ],
   "source": [
    "regAll(l_stain0_filter[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 387/387 [4:23:49<00:00, 40.90s/it]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5h 21min 46s (started: 2022-01-06 17:04:10 -06:00)\n"
     ]
    }
   ],
   "source": [
    "# registers all image sets per tile\n",
    "Parallel(n_jobs = int(available_cores * 0.9))(delayed(regAll)(file)for file in tqdm(l_stain0_filter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev mode open random selection of registered stacks to visually confirm successful registration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter for only \"Good\" Tiles, Crop Stacks + Stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tiles = pd.read_csv(output_dir + '/good_tiles.csv', header = None)   # save list of good tiles as good_tiles.csv file in the base output directory.  Column 1 = Row, Column 2 = Column, Column 3 = Slide\n",
    "tiles_in = []\n",
    "for x in good_tiles.values.tolist():\n",
    "    tiles_in.append((x[0], x[1], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all 'stack' files\n",
    "l_stacks = []\n",
    "for root, dirs, files in os.walk(reg_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('_stack.tiff'):\n",
    "            l_stacks.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_l_files = [file for file in l_files if os.path.basename(file).startswith('Aligned_0')]   #list of 1 image from each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in sort_l_files:\n",
    "    _, _, _, slide_ID, _ = os.path.basename(p).split('_')\n",
    "\n",
    "    stack_meta = {}\n",
    "    for path in l_stacks:\n",
    "        file = os.path.basename(os.path.splitext(path)[0])\n",
    "        slide,row, col, _ = file.split('_')\n",
    "        int_row = row[1:]\n",
    "        int_col = col[1:]\n",
    "        coord = (int(int_row), int(int_col), str(slide))\n",
    "        if slide == slide_ID:\n",
    "            if coord in tiles_in:                 # Checks if each coord is listed in users's good_tiles list.  Can comment out this line if all tiles are considered 'good'\n",
    "                stack_meta[coord] = path\n",
    "\n",
    "    img = io.imread(p)   # reads image shape without reading full image\n",
    "    num_rows = list(range(int(img.shape[0]/tile_x)))\n",
    "    num_cols = list(range(int(img.shape[1]/tile_y)))\n",
    "    combined = [(f,s, slide) for f in num_rows for s in num_cols] \n",
    "\n",
    "    l_CropPath = []\n",
    "    for item in combined:\n",
    "        if item in stack_meta.keys():\n",
    "            l_CropPath.append((item, stack_meta[item]))\n",
    "        else:\n",
    "            l_CropPath.append((item, 'placeholder'))\n",
    "\n",
    "    l_crops = []\n",
    "    for item in l_CropPath:\n",
    "        if item[1] == 'placeholder':\n",
    "            l_crops.append(np.zeros((len(stain_order),tile_x,tile_y,3), dtype = np.uint8))\n",
    "        else:\n",
    "            row = item[0][0]\n",
    "            col = item[0][1]\n",
    "            if row == 0:\n",
    "                row_top_offset = 0\n",
    "            else:\n",
    "                row_top_offset = overlap_x\n",
    "            if row == int(img.shape[0]/tile_x)-1:\n",
    "                row_bot_offset = 0\n",
    "            else:\n",
    "                row_bot_offset = overlap_x\n",
    "            if col == 0:\n",
    "                col_l_offset = 0\n",
    "            else:\n",
    "                col_l_offset = overlap_y\n",
    "            if col == int(img.shape[1]/tile_y)-1:\n",
    "                col_r_offset = 0\n",
    "            else:\n",
    "                col_r_offset = overlap_y\n",
    "            cropped_img = crop(io.imread(item[1]), ((0,0), (row_top_offset, row_bot_offset), (col_l_offset, col_r_offset), (0,0)), copy = False)\n",
    "            l_crops.append(cropped_img)\n",
    "            assert cropped_img.shape == (len(stain_order),tile_x, tile_y,3)\n",
    "            tifffile.imwrite(crops_folder + '/{}_r{}_c{}_cropped.tiff'.format(item[0][2],item[0][0], item[0][1]), cropped_img)    # crop off overlap pixels and save as final registered stack tiles\n",
    "    conc_rows = []\n",
    "    for x in range(len(num_rows)):\n",
    "        conc_rows.append((np.concatenate(l_crops[((max(num_cols)+1)*(x)):((max(num_cols)+1)*(x+1))], axis = 2)))\n",
    "    conc_all = np.concatenate(conc_rows, axis = 1)\n",
    "\n",
    "    tifffile.imwrite(stitch_folder + f'/{slide_ID}_stitched.tiff', conc_all)   # stitch all stacks together for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Napari Visualization of Stitched Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL and depending on PC specs may not work with insufficent memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_full_stitch = []\n",
    "\n",
    "for root, dirs, files in os.walk(output_dir + '/StitchedSlides/'):\n",
    "    for file in files:\n",
    "        if file.endswith('_stitched.tiff'):\n",
    "            l_full_stitch.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "if dev_mode == True:\n",
    "    file = l_full_stitch[0]   # edit int value to choose which slide to visualize\n",
    "\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(tifffile.imread(file), name = os.path.basename(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stardist Segmentation of Tiles and Readout Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(image):\n",
    "    if type(image) == str:\n",
    "        img = io.imread(image)\n",
    "        hax  = separate_stains(img, hax_from_rgb)\n",
    "        hema = hax[:,:,0]\n",
    "        h = rescale_intensity(hema, in_range = (0, 1), out_range = 'uint8')   # edit in-range for better isolation of hematoxylin signal\n",
    "        \n",
    "        aec = hax[:,:,1]\n",
    "        a = rescale_intensity(aec, in_range = (0,1), out_range = 'uint8')\n",
    "    elif type(image) == np.ndarray:\n",
    "        hax = separate_stains(image, hax_from_rgb)\n",
    "        hema = hax[:,:,0]\n",
    "        h = rescale_intensity(hema, in_range = (0, 1), out_range = 'uint8')\n",
    "        \n",
    "        aec = hax[:,:,1]\n",
    "        a = rescale_intensity(aec, in_range = (0,1), out_range = 'uint8')\n",
    "    return h, a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(stardist_dir) \n",
    "model = StarDist2D(None, name='stardist_7_13', basedir='models')\n",
    "\n",
    "axis_norm = (0,1)\n",
    "n_channel = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cropped_stacks = []   # list of dicts, single dict per slide, within dict:  tile_x, tile_y, slide_id  =  stack array\n",
    "for x in slide_id:\n",
    "    d_cropped_stacks = {}\n",
    "    for root, dirs, files in os.walk(crops_folder):\n",
    "        for i in files:\n",
    "            if i.endswith('_cropped.tiff'):\n",
    "                if i.startswith(x):\n",
    "                    array = io.imread(os.path.join(root,i))\n",
    "                    pat, row, col, _ = i.split('_')\n",
    "                    tile = (int(row[1:]), int(col[1:]), pat)\n",
    "                    d_cropped_stacks[tile] = array\n",
    "    l_cropped_stacks.append(d_cropped_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for reading labels from external source\n",
    "if batch_mode == False: \n",
    "    if stardist_segmentation == True:\n",
    "        for y in [l_cropped_stacks[test_slide_index]]:    #  to only compute for 1 slide\n",
    "            df_all = pd.DataFrame()\n",
    "            d_labels = {}\n",
    "            d_expanded_labels = {}\n",
    "\n",
    "            for tile, array in y.items():\n",
    "                df_int = pd.DataFrame()\n",
    "                seg = deconv(array[4])\n",
    "                norm = normalize(seg[0], 1, 99.8, axis = axis_norm)\n",
    "                labels, details = model.predict_instances(norm)\n",
    "\n",
    "                d_labels[tile] = labels\n",
    "\n",
    "                exp_lab = expand_labels(labels, distance = exp_lab_dist)   \n",
    "\n",
    "                d_expanded_labels[tile] = exp_lab\n",
    "\n",
    "                #save labels\n",
    "                io.imsave(labels_folder + '/{}_r{}_c{}_labels.tiff'.format(tile[2], tile[0], tile[1]), labels)\n",
    "                if dev_mode == True:\n",
    "                    io.imsave(labels_folder + '/{}_r{}_c{}_seg.tiff'.format(tile[2], tile[0], tile[1]), seg[0])   # saves deconvoluted image that stardist works on\n",
    "                    io.imsave(labels_folder + '/{}_r{}_c{}_seg_raw.tiff'.format(tile[2], tile[0], tile[1]), array[5])  # saves raw pre-deconvolution image \n",
    "\n",
    "\n",
    "                for i in range(array.shape[0]):\n",
    "                    int_img = deconv(array[i])[1]\n",
    "                    nuc_props = regionprops_table(label_image = labels, intensity_image = int_img, \n",
    "                                              properties = ('label', 'centroid', 'mean_intensity'))\n",
    "                    nuc_data = pd.DataFrame(nuc_props)\n",
    "                    nuc_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_nuc'}, inplace = True)\n",
    "\n",
    "                    cell_props = regionprops_table(label_image = exp_lab, intensity_image = int_img, \n",
    "                                              properties = ('label', 'mean_intensity'))\n",
    "                    cell_data = pd.DataFrame(cell_props)\n",
    "                    cell_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_cell'}, inplace = True)\n",
    "\n",
    "                    data = nuc_data.merge(cell_data, on = 'label')\n",
    "\n",
    "                    if i != 0:\n",
    "                        data = data.drop(['centroid-1', 'centroid-0'], axis = 1)\n",
    "\n",
    "                    if i == 0:\n",
    "                        data.insert(1, 'Tile', str(tile))\n",
    "                        data.insert(1, 'Tile_row', tile[0])\n",
    "                        data.insert(2, 'Tile_col', tile[1])\n",
    "                        data['Global_y'] = data['centroid-0']+(data['Tile_row']*float(tile_x))\n",
    "                        data['Global_x'] = data['centroid-1']+(data['Tile_col']*float(tile_y))\n",
    "                        df_int = data\n",
    "                    else:\n",
    "                        df_int = df_int.merge(data, on = 'label')\n",
    "                try:\n",
    "                    df_all = df_all.append(df_int, ignore_index = True)\n",
    "                except:\n",
    "                    df_all = df_int\n",
    "            df_all.to_csv(output_dir + '/{}_export.csv'.format(tile[2]))\n",
    "    else:\n",
    "        d_labels = {}\n",
    "        for ii in glob.glob(labels_folder + '/*labels.tiff'):\n",
    "            pat, row, col, _ = os.path.basename(ii).split('_')\n",
    "            tile = (int(row[1:]), int(col[1:]), pat)\n",
    "        for y in [l_cropped_stacks[test_slide_index]]:\n",
    "            df_all = pd.DataFrame()\n",
    "\n",
    "            for tile, array in y.items():\n",
    "                labels = d_labels[tile]\n",
    "                exp_lab = expand_labels(labels, distance = exp_lab_dist)   \n",
    "\n",
    "                for i in range(array.shape[0]):\n",
    "                    int_img = deconv(array[i])[1]\n",
    "                    nuc_props = regionprops_table(label_image = labels, intensity_image = int_img, \n",
    "                                              properties = ('label', 'centroid', 'mean_intensity'))\n",
    "                    nuc_data = pd.DataFrame(nuc_props)\n",
    "                    nuc_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_nuc'}, inplace = True)\n",
    "\n",
    "                    cell_props = regionprops_table(label_image = exp_lab, intensity_image = int_img, \n",
    "                                              properties = ('label', 'mean_intensity'))\n",
    "                    cell_data = pd.DataFrame(cell_props)\n",
    "                    cell_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_cell'}, inplace = True)\n",
    "\n",
    "                    data = nuc_data.merge(cell_data, on = 'label')\n",
    "\n",
    "                    if i != 0:\n",
    "                        data = data.drop(['centroid-1', 'centroid-0'], axis = 1)\n",
    "\n",
    "                    if i == 0:\n",
    "                        data.insert(1, 'Tile', str(tile))\n",
    "                        data.insert(1, 'Tile_row', tile[0])\n",
    "                        data.insert(2, 'Tile_col', tile[1])\n",
    "                        data['Global_y'] = data['centroid-0']+(data['Tile_row']*float(tile_x))\n",
    "                        data['Global_x'] = data['centroid-1']+(data['Tile_col']*float(tile_y))\n",
    "                        df_int = data\n",
    "                    else:\n",
    "                        df_int = df_int.merge(data, on = 'label')\n",
    "                try:\n",
    "                    df_all = df_all.append(df_int, ignore_index = True)\n",
    "                except:\n",
    "                    df_all = df_int\n",
    "            df_all.to_csv(output_dir + '/{}_export.csv'.format(tile[2]))\n",
    "else:\n",
    "    if stardist_segmentation == True:\n",
    "        for y in l_cropped_stacks:  \n",
    "            df_all = pd.DataFrame()\n",
    "            d_labels = {}\n",
    "            d_expanded_labels = {}\n",
    "\n",
    "            for tile, array in y.items():\n",
    "                df_int = pd.DataFrame()\n",
    "                seg = deconv(array[4])\n",
    "                norm = normalize(seg[0], 1, 99.8, axis = axis_norm)\n",
    "                labels, details = model.predict_instances(norm)\n",
    "\n",
    "                d_labels[tile] = labels\n",
    "\n",
    "                exp_lab = expand_labels(labels, distance = exp_lab_dist)   \n",
    "\n",
    "                d_expanded_labels[tile] = exp_lab\n",
    "\n",
    "                #save labels\n",
    "                io.imsave(labels_folder + '/{}_r{}_c{}_labels.tiff'.format(tile[2], tile[0], tile[1]), labels)\n",
    "                if dev_mode == True:\n",
    "                    io.imsave(labels_folder + '/{}_r{}_c{}_seg.tiff'.format(tile[2], tile[0], tile[1]), seg[0])   # saves deconvoluted image that stardist works on\n",
    "                    io.imsave(labels_folder + '/{}_r{}_c{}_seg_raw.tiff'.format(tile[2], tile[0], tile[1]), array[5])  # saves raw pre-deconvolution image \n",
    "\n",
    "\n",
    "                for i in range(array.shape[0]):\n",
    "                    int_img = deconv(array[i])[1]\n",
    "                    nuc_props = regionprops_table(label_image = labels, intensity_image = int_img, \n",
    "                                              properties = ('label', 'centroid', 'mean_intensity'))\n",
    "                    nuc_data = pd.DataFrame(nuc_props)\n",
    "                    nuc_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_nuc'}, inplace = True)\n",
    "\n",
    "                    cell_props = regionprops_table(label_image = exp_lab, intensity_image = int_img, \n",
    "                                              properties = ('label', 'mean_intensity'))\n",
    "                    cell_data = pd.DataFrame(cell_props)\n",
    "                    cell_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_cell'}, inplace = True)\n",
    "\n",
    "                    data = nuc_data.merge(cell_data, on = 'label')\n",
    "\n",
    "                    if i != 0:\n",
    "                        data = data.drop(['centroid-1', 'centroid-0'], axis = 1)\n",
    "\n",
    "                    if i == 0:\n",
    "                        data.insert(1, 'Tile', str(tile))\n",
    "                        data.insert(1, 'Tile_row', tile[0])\n",
    "                        data.insert(2, 'Tile_col', tile[1])\n",
    "                        data['Global_y'] = data['centroid-0']+(data['Tile_row']*float(tile_x))\n",
    "                        data['Global_x'] = data['centroid-1']+(data['Tile_col']*float(tile_y))\n",
    "                        df_int = data\n",
    "                    else:\n",
    "                        df_int = df_int.merge(data, on = 'label')\n",
    "                try:\n",
    "                    df_all = df_all.append(df_int, ignore_index = True)\n",
    "                except:\n",
    "                    df_all = df_int\n",
    "            df_all.to_csv(output_dir + '/{}_export.csv'.format(tile[2]))\n",
    "        else:\n",
    "            d_labels = {}\n",
    "            for ii in glob.glob(labels_folder + '/*labels.tiff'):\n",
    "                pat, row, col, _ = os.path.basename(ii).split('_')\n",
    "                tile = (int(row[1:]), int(col[1:]), pat)\n",
    "            for y in l_cropped_stacks:\n",
    "                df_all = pd.DataFrame()\n",
    "\n",
    "                for tile, array in y.items():\n",
    "                    labels = d_labels[tile]\n",
    "                    exp_lab = expand_labels(labels, distance = exp_lab_dist)   \n",
    "\n",
    "                    for i in range(array.shape[0]):\n",
    "                        int_img = deconv(array[i])[1]\n",
    "                        nuc_props = regionprops_table(label_image = labels, intensity_image = int_img, \n",
    "                                                  properties = ('label', 'centroid', 'mean_intensity'))\n",
    "                        nuc_data = pd.DataFrame(nuc_props)\n",
    "                        nuc_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_nuc'}, inplace = True)\n",
    "\n",
    "                        cell_props = regionprops_table(label_image = exp_lab, intensity_image = int_img, \n",
    "                                                  properties = ('label', 'mean_intensity'))\n",
    "                        cell_data = pd.DataFrame(cell_props)\n",
    "                        cell_data.rename(columns = {'mean_intensity': 'mean_intensity_' + stain_order[i] + '_cell'}, inplace = True)\n",
    "\n",
    "                        data = nuc_data.merge(cell_data, on = 'label')\n",
    "\n",
    "                        if i != 0:\n",
    "                            data = data.drop(['centroid-1', 'centroid-0'], axis = 1)\n",
    "\n",
    "                        if i == 0:\n",
    "                            data.insert(1, 'Tile', str(tile))\n",
    "                            data.insert(1, 'Tile_row', tile[0])\n",
    "                            data.insert(2, 'Tile_col', tile[1])\n",
    "                            data['Global_y'] = data['centroid-0']+(data['Tile_row']*float(tile_x))\n",
    "                            data['Global_x'] = data['centroid-1']+(data['Tile_col']*float(tile_y))\n",
    "                            df_int = data\n",
    "                        else:\n",
    "                            df_int = df_int.merge(data, on = 'label')\n",
    "                    try:\n",
    "                        df_all = df_all.append(df_int, ignore_index = True)\n",
    "                    except:\n",
    "                        df_all = df_int\n",
    "                df_all.to_csv(output_dir + '/{}_export.csv'.format(tile[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(output_dir + '/df_all.csv')    # save all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(output_dir + '/df_all.csv')   # load all features.  Can skip to this step if above has already been run and only visualizations below are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole Slide Psudocolor Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_all.columns:\n",
    "    print(column)\n",
    "feature = 'mean_intensity_CD68_cell'    # string for specific feature of interest. Copy and paste from printed strings below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figure of all detections scatter of full slide\n",
    "if batch_mode == False:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    ax = sns.scatterplot(data = df_all, x = 'Global_x', y = 'Global_y', hue = feature, hue_norm = (0, 100), palette = 'viridis', linewidth=0, s =10)\n",
    "    ax.set_aspect(aspect = 1)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(f'{plots_folder}/{feature}_{slide_id[test_slide_index]}.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_mode == False:\n",
    "    df_heatmap = df_all.groupby(['Tile']).mean(feature)[['Tile_row', 'Tile_col', feature]]\n",
    "    df_heatmap['Tile_row'] = df_heatmap['Tile_row'].astype(int)\n",
    "    df_heatmap['Tile_col'] = df_heatmap['Tile_col'].astype(int)\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    ax = sns.scatterplot(data = df_heatmap, y = 'Tile_row', x = 'Tile_col', hue = feature, palette = 'viridis', \n",
    "                         s = 600, marker = 's')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend(bbox_to_anchor = (0,1), loc = 'upper left', ncol =1)\n",
    "    plt.title(f'Per Tile Expression {feature}')\n",
    "    ax.set_aspect(aspect = 1)\n",
    "    plt.savefig(f'{plots_folder}/Per_Tile_{feature}_{slide_id[test_slide_index]}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Voronoi Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create voronoi diagram for selected tile with each cell polygon's color indicating the measured intensity of a feature of interest\n",
    "# Next cell will list out available options for tile selection and feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tile in sorted(df_all['Tile'].unique()):\n",
    "    print(tile)\n",
    "\n",
    "for column in df_all.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_in = \"(1, 3, 'N16-244-2A')\"       # string for specific tile of interest. Make sure string perfectly matches\n",
    "feature = 'mean_intensity_PD-L1_nuc'    # string for specific feature of interest. Make sure string perfectly matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tile = df_all[df_all['Tile'] == tile_in].reset_index()\n",
    "\n",
    "coords = np.asarray(df_tile[['centroid-1', 'centroid-0']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import Delaunay, Voronoi, voronoi_plot_2d\n",
    "\n",
    "vor = Voronoi(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "fig = voronoi_plot_2d(vor, show_vertices = False, show_points = False)\n",
    "fig.set_size_inches(10,10)\n",
    "c = df_tile[feature]\n",
    "minima = min(c)\n",
    "maxima = max(c)\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "\n",
    "\n",
    "for r in range(len(vor.point_region)):\n",
    "    region = vor.regions[vor.point_region[r]]\n",
    "    if not -1 in region:\n",
    "        polygon = [vor.vertices[i] for i in region]\n",
    "        plt.fill(*zip(*polygon), color=mapper.to_rgba(c[r]))\n",
    "        \n",
    "plt.ylim(0,2048)\n",
    "plt.xlim(0, 2048)\n",
    "\n",
    "plt.savefig(f'{plots_folder}/Vor_demo{feature}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
